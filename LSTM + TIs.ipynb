{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c42dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 2070 Super with Max-Q Design (UUID: GPU-bf3c05f4-d285-42f9-9239-aae61d4ea191)\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "545692e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2756c558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Id</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>SMA_7</th>\n",
       "      <th>SMA_14</th>\n",
       "      <th>...</th>\n",
       "      <th>PSARr_0.02_0.2</th>\n",
       "      <th>AROOND_14</th>\n",
       "      <th>AROONU_14</th>\n",
       "      <th>AROONOSC_14</th>\n",
       "      <th>STOCHk_14_3_3</th>\n",
       "      <th>STOCHd_14_3_3</th>\n",
       "      <th>MACD_12_26_9</th>\n",
       "      <th>MACDh_12_26_9</th>\n",
       "      <th>MACDs_12_26_9</th>\n",
       "      <th>KAMA_10_2_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-13 11:15:00+05:30</td>\n",
       "      <td>33</td>\n",
       "      <td>0.260655</td>\n",
       "      <td>0.258264</td>\n",
       "      <td>0.270536</td>\n",
       "      <td>0.261868</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0.263339</td>\n",
       "      <td>0.261930</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>-1763.647282</td>\n",
       "      <td>-1675.479655</td>\n",
       "      <td>0.003290</td>\n",
       "      <td>-0.000246</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>0.246675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-13 11:30:00+05:30</td>\n",
       "      <td>34</td>\n",
       "      <td>0.259364</td>\n",
       "      <td>0.257929</td>\n",
       "      <td>0.269662</td>\n",
       "      <td>0.262588</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0.263171</td>\n",
       "      <td>0.262111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.714286</td>\n",
       "      <td>35.714286</td>\n",
       "      <td>-8.622299</td>\n",
       "      <td>-1153.427392</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>-0.000334</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>0.247075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-13 11:45:00+05:30</td>\n",
       "      <td>35</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.259107</td>\n",
       "      <td>0.271068</td>\n",
       "      <td>0.263545</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0.263218</td>\n",
       "      <td>0.262479</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>55.026650</td>\n",
       "      <td>-572.414310</td>\n",
       "      <td>0.003025</td>\n",
       "      <td>-0.000342</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.247542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-13 12:00:00+05:30</td>\n",
       "      <td>36</td>\n",
       "      <td>0.261016</td>\n",
       "      <td>0.258817</td>\n",
       "      <td>0.271851</td>\n",
       "      <td>0.263819</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0.263273</td>\n",
       "      <td>0.262923</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>57.978114</td>\n",
       "      <td>34.794155</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.247627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-13 12:15:00+05:30</td>\n",
       "      <td>37</td>\n",
       "      <td>0.261278</td>\n",
       "      <td>0.259025</td>\n",
       "      <td>0.271392</td>\n",
       "      <td>0.263025</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0.263065</td>\n",
       "      <td>0.263128</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>59.958207</td>\n",
       "      <td>57.654324</td>\n",
       "      <td>0.002774</td>\n",
       "      <td>-0.000406</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.247873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25462</th>\n",
       "      <td>2019-02-28 10:30:00+05:30</td>\n",
       "      <td>25495</td>\n",
       "      <td>0.711045</td>\n",
       "      <td>0.711635</td>\n",
       "      <td>0.721231</td>\n",
       "      <td>0.718972</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>0.716356</td>\n",
       "      <td>0.715153</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.285714</td>\n",
       "      <td>64.285714</td>\n",
       "      <td>129.227651</td>\n",
       "      <td>113.482826</td>\n",
       "      <td>-0.000656</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>-0.001550</td>\n",
       "      <td>0.714781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25463</th>\n",
       "      <td>2019-02-28 10:45:00+05:30</td>\n",
       "      <td>25496</td>\n",
       "      <td>0.712138</td>\n",
       "      <td>0.712070</td>\n",
       "      <td>0.720268</td>\n",
       "      <td>0.717022</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>0.717192</td>\n",
       "      <td>0.715279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.142857</td>\n",
       "      <td>57.142857</td>\n",
       "      <td>134.556715</td>\n",
       "      <td>124.950021</td>\n",
       "      <td>-0.000532</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>-0.001346</td>\n",
       "      <td>0.714912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25464</th>\n",
       "      <td>2019-02-28 11:00:00+05:30</td>\n",
       "      <td>25497</td>\n",
       "      <td>0.710287</td>\n",
       "      <td>0.710058</td>\n",
       "      <td>0.719988</td>\n",
       "      <td>0.716538</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>0.717063</td>\n",
       "      <td>0.715391</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>129.093591</td>\n",
       "      <td>130.959319</td>\n",
       "      <td>-0.000467</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>-0.001170</td>\n",
       "      <td>0.714996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25465</th>\n",
       "      <td>2019-02-28 11:15:00+05:30</td>\n",
       "      <td>25498</td>\n",
       "      <td>0.709853</td>\n",
       "      <td>0.709922</td>\n",
       "      <td>0.719988</td>\n",
       "      <td>0.717085</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>0.717277</td>\n",
       "      <td>0.715434</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>115.100027</td>\n",
       "      <td>126.250111</td>\n",
       "      <td>-0.000367</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>-0.001010</td>\n",
       "      <td>0.715056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25466</th>\n",
       "      <td>2019-02-28 11:30:00+05:30</td>\n",
       "      <td>25499</td>\n",
       "      <td>0.710359</td>\n",
       "      <td>0.710022</td>\n",
       "      <td>0.720232</td>\n",
       "      <td>0.717195</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>0.717317</td>\n",
       "      <td>0.715599</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>35.714286</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>116.706949</td>\n",
       "      <td>120.300189</td>\n",
       "      <td>-0.000275</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>-0.000863</td>\n",
       "      <td>0.715250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25467 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            date     Id      open      high       low  \\\n",
       "0      2015-01-13 11:15:00+05:30     33  0.260655  0.258264  0.270536   \n",
       "1      2015-01-13 11:30:00+05:30     34  0.259364  0.257929  0.269662   \n",
       "2      2015-01-13 11:45:00+05:30     35  0.260014  0.259107  0.271068   \n",
       "3      2015-01-13 12:00:00+05:30     36  0.261016  0.258817  0.271851   \n",
       "4      2015-01-13 12:15:00+05:30     37  0.261278  0.259025  0.271392   \n",
       "...                          ...    ...       ...       ...       ...   \n",
       "25462  2019-02-28 10:30:00+05:30  25495  0.711045  0.711635  0.721231   \n",
       "25463  2019-02-28 10:45:00+05:30  25496  0.712138  0.712070  0.720268   \n",
       "25464  2019-02-28 11:00:00+05:30  25497  0.710287  0.710058  0.719988   \n",
       "25465  2019-02-28 11:15:00+05:30  25498  0.709853  0.709922  0.719988   \n",
       "25466  2019-02-28 11:30:00+05:30  25499  0.710359  0.710022  0.720232   \n",
       "\n",
       "          close  day  week     SMA_7    SMA_14  ...  PSARr_0.02_0.2  \\\n",
       "0      0.261868   13     3  0.263339  0.261930  ...               0   \n",
       "1      0.262588   13     3  0.263171  0.262111  ...               0   \n",
       "2      0.263545   13     3  0.263218  0.262479  ...               0   \n",
       "3      0.263819   13     3  0.263273  0.262923  ...               0   \n",
       "4      0.263025   13     3  0.263065  0.263128  ...               0   \n",
       "...         ...  ...   ...       ...       ...  ...             ...   \n",
       "25462  0.718972   28     9  0.716356  0.715153  ...               0   \n",
       "25463  0.717022   28     9  0.717192  0.715279  ...               0   \n",
       "25464  0.716538   28     9  0.717063  0.715391  ...               0   \n",
       "25465  0.717085   28     9  0.717277  0.715434  ...               0   \n",
       "25466  0.717195   28     9  0.717317  0.715599  ...               0   \n",
       "\n",
       "       AROOND_14  AROONU_14  AROONOSC_14  STOCHk_14_3_3  STOCHd_14_3_3  \\\n",
       "0       0.000000  42.857143    42.857143   -1763.647282   -1675.479655   \n",
       "1       0.000000  35.714286    35.714286      -8.622299   -1153.427392   \n",
       "2       7.142857  28.571429    21.428571      55.026650    -572.414310   \n",
       "3       0.000000  21.428571    21.428571      57.978114      34.794155   \n",
       "4       0.000000  14.285714    14.285714      59.958207      57.654324   \n",
       "...          ...        ...          ...            ...            ...   \n",
       "25462   0.000000  64.285714    64.285714     129.227651     113.482826   \n",
       "25463   0.000000  57.142857    57.142857     134.556715     124.950021   \n",
       "25464  28.571429  50.000000    21.428571     129.093591     130.959319   \n",
       "25465  21.428571  42.857143    21.428571     115.100027     126.250111   \n",
       "25466  14.285714  35.714286    21.428571     116.706949     120.300189   \n",
       "\n",
       "       MACD_12_26_9  MACDh_12_26_9  MACDs_12_26_9  KAMA_10_2_30  \n",
       "0          0.003290      -0.000246       0.003536      0.246675  \n",
       "1          0.003118      -0.000334       0.003453      0.247075  \n",
       "2          0.003025      -0.000342       0.003367      0.247542  \n",
       "3          0.002939      -0.000343       0.003281      0.247627  \n",
       "4          0.002774      -0.000406       0.003180      0.247873  \n",
       "...             ...            ...            ...           ...  \n",
       "25462     -0.000656       0.000894      -0.001550      0.714781  \n",
       "25463     -0.000532       0.000815      -0.001346      0.714912  \n",
       "25464     -0.000467       0.000704      -0.001170      0.714996  \n",
       "25465     -0.000367       0.000643      -0.001010      0.715056  \n",
       "25466     -0.000275       0.000587      -0.000863      0.715250  \n",
       "\n",
       "[25467 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"TRAINING_SET_FINAL.csv\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "290a0d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = pd.read_csv(\"train_target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8288075d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25495</th>\n",
       "      <td>25495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25496</th>\n",
       "      <td>25496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25497</th>\n",
       "      <td>25497</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25498</th>\n",
       "      <td>25498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25499</th>\n",
       "      <td>25499</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  target\n",
       "0          0       1\n",
       "1          1       0\n",
       "2          2       1\n",
       "3          3       0\n",
       "4          4       0\n",
       "...      ...     ...\n",
       "25495  25495       0\n",
       "25496  25496       1\n",
       "25497  25497       1\n",
       "25498  25498       0\n",
       "25499  25499       0\n",
       "\n",
       "[25500 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0f50976",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_target[\"target\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92d527b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766c5591",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels[32:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71255651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d1c578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.DataFrame(labels,columns = [\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8321722b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25463</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25464</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25465</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25466</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25467</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25468 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target\n",
       "0           1\n",
       "1           1\n",
       "2           1\n",
       "3           0\n",
       "4           0\n",
       "...       ...\n",
       "25463       0\n",
       "25464       1\n",
       "25465       1\n",
       "25466       0\n",
       "25467       0\n",
       "\n",
       "[25468 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5e2360",
   "metadata": {},
   "source": [
    "# SPLITTING INTO TRAINING AND TESTING DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b467b4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Id</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>SMA_7</th>\n",
       "      <th>SMA_14</th>\n",
       "      <th>...</th>\n",
       "      <th>AROOND_14</th>\n",
       "      <th>AROONU_14</th>\n",
       "      <th>AROONOSC_14</th>\n",
       "      <th>STOCHk_14_3_3</th>\n",
       "      <th>STOCHd_14_3_3</th>\n",
       "      <th>MACD_12_26_9</th>\n",
       "      <th>MACDh_12_26_9</th>\n",
       "      <th>MACDs_12_26_9</th>\n",
       "      <th>KAMA_10_2_30</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25462</th>\n",
       "      <td>2019-02-28 10:30:00+05:30</td>\n",
       "      <td>25495</td>\n",
       "      <td>0.711045</td>\n",
       "      <td>0.711635</td>\n",
       "      <td>0.721231</td>\n",
       "      <td>0.718972</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>0.716356</td>\n",
       "      <td>0.715153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.285714</td>\n",
       "      <td>64.285714</td>\n",
       "      <td>129.227651</td>\n",
       "      <td>113.482826</td>\n",
       "      <td>-0.000656</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>-0.001550</td>\n",
       "      <td>0.714781</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25463</th>\n",
       "      <td>2019-02-28 10:45:00+05:30</td>\n",
       "      <td>25496</td>\n",
       "      <td>0.712138</td>\n",
       "      <td>0.712070</td>\n",
       "      <td>0.720268</td>\n",
       "      <td>0.717022</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>0.717192</td>\n",
       "      <td>0.715279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.142857</td>\n",
       "      <td>57.142857</td>\n",
       "      <td>134.556715</td>\n",
       "      <td>124.950021</td>\n",
       "      <td>-0.000532</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>-0.001346</td>\n",
       "      <td>0.714912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25464</th>\n",
       "      <td>2019-02-28 11:00:00+05:30</td>\n",
       "      <td>25497</td>\n",
       "      <td>0.710287</td>\n",
       "      <td>0.710058</td>\n",
       "      <td>0.719988</td>\n",
       "      <td>0.716538</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>0.717063</td>\n",
       "      <td>0.715391</td>\n",
       "      <td>...</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>129.093591</td>\n",
       "      <td>130.959319</td>\n",
       "      <td>-0.000467</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>-0.001170</td>\n",
       "      <td>0.714996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25465</th>\n",
       "      <td>2019-02-28 11:15:00+05:30</td>\n",
       "      <td>25498</td>\n",
       "      <td>0.709853</td>\n",
       "      <td>0.709922</td>\n",
       "      <td>0.719988</td>\n",
       "      <td>0.717085</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>0.717277</td>\n",
       "      <td>0.715434</td>\n",
       "      <td>...</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>115.100027</td>\n",
       "      <td>126.250111</td>\n",
       "      <td>-0.000367</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>-0.001010</td>\n",
       "      <td>0.715056</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25466</th>\n",
       "      <td>2019-02-28 11:30:00+05:30</td>\n",
       "      <td>25499</td>\n",
       "      <td>0.710359</td>\n",
       "      <td>0.710022</td>\n",
       "      <td>0.720232</td>\n",
       "      <td>0.717195</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>0.717317</td>\n",
       "      <td>0.715599</td>\n",
       "      <td>...</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>35.714286</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>116.706949</td>\n",
       "      <td>120.300189</td>\n",
       "      <td>-0.000275</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>-0.000863</td>\n",
       "      <td>0.715250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            date     Id      open      high       low  \\\n",
       "25462  2019-02-28 10:30:00+05:30  25495  0.711045  0.711635  0.721231   \n",
       "25463  2019-02-28 10:45:00+05:30  25496  0.712138  0.712070  0.720268   \n",
       "25464  2019-02-28 11:00:00+05:30  25497  0.710287  0.710058  0.719988   \n",
       "25465  2019-02-28 11:15:00+05:30  25498  0.709853  0.709922  0.719988   \n",
       "25466  2019-02-28 11:30:00+05:30  25499  0.710359  0.710022  0.720232   \n",
       "\n",
       "          close  day  week     SMA_7    SMA_14  ...  AROOND_14  AROONU_14  \\\n",
       "25462  0.718972   28     9  0.716356  0.715153  ...   0.000000  64.285714   \n",
       "25463  0.717022   28     9  0.717192  0.715279  ...   0.000000  57.142857   \n",
       "25464  0.716538   28     9  0.717063  0.715391  ...  28.571429  50.000000   \n",
       "25465  0.717085   28     9  0.717277  0.715434  ...  21.428571  42.857143   \n",
       "25466  0.717195   28     9  0.717317  0.715599  ...  14.285714  35.714286   \n",
       "\n",
       "       AROONOSC_14  STOCHk_14_3_3  STOCHd_14_3_3  MACD_12_26_9  MACDh_12_26_9  \\\n",
       "25462    64.285714     129.227651     113.482826     -0.000656       0.000894   \n",
       "25463    57.142857     134.556715     124.950021     -0.000532       0.000815   \n",
       "25464    21.428571     129.093591     130.959319     -0.000467       0.000704   \n",
       "25465    21.428571     115.100027     126.250111     -0.000367       0.000643   \n",
       "25466    21.428571     116.706949     120.300189     -0.000275       0.000587   \n",
       "\n",
       "       MACDs_12_26_9  KAMA_10_2_30  target  \n",
       "25462      -0.001550      0.714781       0  \n",
       "25463      -0.001346      0.714912       0  \n",
       "25464      -0.001170      0.714996       1  \n",
       "25465      -0.001010      0.715056       1  \n",
       "25466      -0.000863      0.715250       0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"target\"] = train_labels[\"target\"] \n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15fa6273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20373, 32), (5094, 32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df,test_df = train_test_split(train,test_size=0.2,shuffle=False)\n",
    "train_df.shape,test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68a61679",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop([\"Id\",\"week\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "492120eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>day</th>\n",
       "      <th>SMA_7</th>\n",
       "      <th>SMA_14</th>\n",
       "      <th>SMA_21</th>\n",
       "      <th>RSI_7</th>\n",
       "      <th>...</th>\n",
       "      <th>AROOND_14</th>\n",
       "      <th>AROONU_14</th>\n",
       "      <th>AROONOSC_14</th>\n",
       "      <th>STOCHk_14_3_3</th>\n",
       "      <th>STOCHd_14_3_3</th>\n",
       "      <th>MACD_12_26_9</th>\n",
       "      <th>MACDh_12_26_9</th>\n",
       "      <th>MACDs_12_26_9</th>\n",
       "      <th>KAMA_10_2_30</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-13 11:15:00+05:30</td>\n",
       "      <td>0.260655</td>\n",
       "      <td>0.258264</td>\n",
       "      <td>0.270536</td>\n",
       "      <td>0.261868</td>\n",
       "      <td>13</td>\n",
       "      <td>0.263339</td>\n",
       "      <td>0.261930</td>\n",
       "      <td>0.258588</td>\n",
       "      <td>53.492162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>-1763.647282</td>\n",
       "      <td>-1675.479655</td>\n",
       "      <td>0.003290</td>\n",
       "      <td>-0.000246</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>0.246675</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-13 11:30:00+05:30</td>\n",
       "      <td>0.259364</td>\n",
       "      <td>0.257929</td>\n",
       "      <td>0.269662</td>\n",
       "      <td>0.262588</td>\n",
       "      <td>13</td>\n",
       "      <td>0.263171</td>\n",
       "      <td>0.262111</td>\n",
       "      <td>0.259153</td>\n",
       "      <td>58.304684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.714286</td>\n",
       "      <td>35.714286</td>\n",
       "      <td>-8.622299</td>\n",
       "      <td>-1153.427392</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>-0.000334</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>0.247075</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-13 11:45:00+05:30</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.259107</td>\n",
       "      <td>0.271068</td>\n",
       "      <td>0.263545</td>\n",
       "      <td>13</td>\n",
       "      <td>0.263218</td>\n",
       "      <td>0.262479</td>\n",
       "      <td>0.259741</td>\n",
       "      <td>64.069883</td>\n",
       "      <td>...</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>55.026650</td>\n",
       "      <td>-572.414310</td>\n",
       "      <td>0.003025</td>\n",
       "      <td>-0.000342</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.247542</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-13 12:00:00+05:30</td>\n",
       "      <td>0.261016</td>\n",
       "      <td>0.258817</td>\n",
       "      <td>0.271851</td>\n",
       "      <td>0.263819</td>\n",
       "      <td>13</td>\n",
       "      <td>0.263273</td>\n",
       "      <td>0.262923</td>\n",
       "      <td>0.260324</td>\n",
       "      <td>65.652936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>57.978114</td>\n",
       "      <td>34.794155</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.247627</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-13 12:15:00+05:30</td>\n",
       "      <td>0.261278</td>\n",
       "      <td>0.259025</td>\n",
       "      <td>0.271392</td>\n",
       "      <td>0.263025</td>\n",
       "      <td>13</td>\n",
       "      <td>0.263065</td>\n",
       "      <td>0.263128</td>\n",
       "      <td>0.260913</td>\n",
       "      <td>57.135864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>59.958207</td>\n",
       "      <td>57.654324</td>\n",
       "      <td>0.002774</td>\n",
       "      <td>-0.000406</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.247873</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20368</th>\n",
       "      <td>2018-05-04 13:00:00+05:30</td>\n",
       "      <td>0.673273</td>\n",
       "      <td>0.672072</td>\n",
       "      <td>0.682240</td>\n",
       "      <td>0.678601</td>\n",
       "      <td>4</td>\n",
       "      <td>0.680032</td>\n",
       "      <td>0.681577</td>\n",
       "      <td>0.684415</td>\n",
       "      <td>22.196814</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>61.074743</td>\n",
       "      <td>12.999437</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.000169</td>\n",
       "      <td>-0.002861</td>\n",
       "      <td>0.681030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20369</th>\n",
       "      <td>2018-05-04 13:15:00+05:30</td>\n",
       "      <td>0.672163</td>\n",
       "      <td>0.673649</td>\n",
       "      <td>0.682276</td>\n",
       "      <td>0.680671</td>\n",
       "      <td>4</td>\n",
       "      <td>0.680159</td>\n",
       "      <td>0.681375</td>\n",
       "      <td>0.683733</td>\n",
       "      <td>42.785621</td>\n",
       "      <td>...</td>\n",
       "      <td>92.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-92.857143</td>\n",
       "      <td>84.167510</td>\n",
       "      <td>54.442974</td>\n",
       "      <td>-0.002876</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.002864</td>\n",
       "      <td>0.681020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20370</th>\n",
       "      <td>2018-05-04 13:30:00+05:30</td>\n",
       "      <td>0.674276</td>\n",
       "      <td>0.674329</td>\n",
       "      <td>0.683600</td>\n",
       "      <td>0.680707</td>\n",
       "      <td>4</td>\n",
       "      <td>0.680324</td>\n",
       "      <td>0.681179</td>\n",
       "      <td>0.683191</td>\n",
       "      <td>43.095194</td>\n",
       "      <td>...</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>-78.571429</td>\n",
       "      <td>50.980438</td>\n",
       "      <td>65.407564</td>\n",
       "      <td>-0.002720</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-0.002835</td>\n",
       "      <td>0.681003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20371</th>\n",
       "      <td>2018-05-04 13:45:00+05:30</td>\n",
       "      <td>0.674330</td>\n",
       "      <td>0.674410</td>\n",
       "      <td>0.683996</td>\n",
       "      <td>0.681227</td>\n",
       "      <td>4</td>\n",
       "      <td>0.680414</td>\n",
       "      <td>0.681033</td>\n",
       "      <td>0.682609</td>\n",
       "      <td>47.791550</td>\n",
       "      <td>...</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-78.571429</td>\n",
       "      <td>26.650238</td>\n",
       "      <td>53.932729</td>\n",
       "      <td>-0.002525</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>-0.002773</td>\n",
       "      <td>0.681009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20372</th>\n",
       "      <td>2018-05-04 14:00:00+05:30</td>\n",
       "      <td>0.674691</td>\n",
       "      <td>0.675561</td>\n",
       "      <td>0.682681</td>\n",
       "      <td>0.679713</td>\n",
       "      <td>4</td>\n",
       "      <td>0.680234</td>\n",
       "      <td>0.680819</td>\n",
       "      <td>0.682136</td>\n",
       "      <td>37.325220</td>\n",
       "      <td>...</td>\n",
       "      <td>71.428571</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>31.647070</td>\n",
       "      <td>36.425916</td>\n",
       "      <td>-0.002465</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>-0.002712</td>\n",
       "      <td>0.681003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20373 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            date      open      high       low     close  day  \\\n",
       "0      2015-01-13 11:15:00+05:30  0.260655  0.258264  0.270536  0.261868   13   \n",
       "1      2015-01-13 11:30:00+05:30  0.259364  0.257929  0.269662  0.262588   13   \n",
       "2      2015-01-13 11:45:00+05:30  0.260014  0.259107  0.271068  0.263545   13   \n",
       "3      2015-01-13 12:00:00+05:30  0.261016  0.258817  0.271851  0.263819   13   \n",
       "4      2015-01-13 12:15:00+05:30  0.261278  0.259025  0.271392  0.263025   13   \n",
       "...                          ...       ...       ...       ...       ...  ...   \n",
       "20368  2018-05-04 13:00:00+05:30  0.673273  0.672072  0.682240  0.678601    4   \n",
       "20369  2018-05-04 13:15:00+05:30  0.672163  0.673649  0.682276  0.680671    4   \n",
       "20370  2018-05-04 13:30:00+05:30  0.674276  0.674329  0.683600  0.680707    4   \n",
       "20371  2018-05-04 13:45:00+05:30  0.674330  0.674410  0.683996  0.681227    4   \n",
       "20372  2018-05-04 14:00:00+05:30  0.674691  0.675561  0.682681  0.679713    4   \n",
       "\n",
       "          SMA_7    SMA_14    SMA_21      RSI_7  ...   AROOND_14  AROONU_14  \\\n",
       "0      0.263339  0.261930  0.258588  53.492162  ...    0.000000  42.857143   \n",
       "1      0.263171  0.262111  0.259153  58.304684  ...    0.000000  35.714286   \n",
       "2      0.263218  0.262479  0.259741  64.069883  ...    7.142857  28.571429   \n",
       "3      0.263273  0.262923  0.260324  65.652936  ...    0.000000  21.428571   \n",
       "4      0.263065  0.263128  0.260913  57.135864  ...    0.000000  14.285714   \n",
       "...         ...       ...       ...        ...  ...         ...        ...   \n",
       "20368  0.680032  0.681577  0.684415  22.196814  ...  100.000000   0.000000   \n",
       "20369  0.680159  0.681375  0.683733  42.785621  ...   92.857143   0.000000   \n",
       "20370  0.680324  0.681179  0.683191  43.095194  ...   85.714286   7.142857   \n",
       "20371  0.680414  0.681033  0.682609  47.791550  ...   78.571429   0.000000   \n",
       "20372  0.680234  0.680819  0.682136  37.325220  ...   71.428571  21.428571   \n",
       "\n",
       "       AROONOSC_14  STOCHk_14_3_3  STOCHd_14_3_3  MACD_12_26_9  MACDh_12_26_9  \\\n",
       "0        42.857143   -1763.647282   -1675.479655      0.003290      -0.000246   \n",
       "1        35.714286      -8.622299   -1153.427392      0.003118      -0.000334   \n",
       "2        21.428571      55.026650    -572.414310      0.003025      -0.000342   \n",
       "3        21.428571      57.978114      34.794155      0.002939      -0.000343   \n",
       "4        14.285714      59.958207      57.654324      0.002774      -0.000406   \n",
       "...            ...            ...            ...           ...            ...   \n",
       "20368  -100.000000      61.074743      12.999437     -0.003030      -0.000169   \n",
       "20369   -92.857143      84.167510      54.442974     -0.002876      -0.000012   \n",
       "20370   -78.571429      50.980438      65.407564     -0.002720       0.000115   \n",
       "20371   -78.571429      26.650238      53.932729     -0.002525       0.000248   \n",
       "20372   -50.000000      31.647070      36.425916     -0.002465       0.000247   \n",
       "\n",
       "       MACDs_12_26_9  KAMA_10_2_30  target  \n",
       "0           0.003536      0.246675       1  \n",
       "1           0.003453      0.247075       1  \n",
       "2           0.003367      0.247542       1  \n",
       "3           0.003281      0.247627       0  \n",
       "4           0.003180      0.247873       0  \n",
       "...              ...           ...     ...  \n",
       "20368      -0.002861      0.681030       1  \n",
       "20369      -0.002864      0.681020       1  \n",
       "20370      -0.002835      0.681003       1  \n",
       "20371      -0.002773      0.681009       0  \n",
       "20372      -0.002712      0.681003       0  \n",
       "\n",
       "[20373 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e35e539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop([\"Id\",\"week\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b922d61",
   "metadata": {},
   "source": [
    "# STANDARDIZING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb8f76a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standard_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db11d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = train_df.drop([\"date\",\"target\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0ab3f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_scaler.fit(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd66d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = standard_scaler.transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0480f2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.53089122, -0.53622276, -0.53121092, ..., -0.28056776,\n",
       "         1.16790542, -0.62370649],\n",
       "       [-0.53823842, -0.53812442, -0.53619273, ..., -0.38152646,\n",
       "         1.13908959, -0.6214498 ],\n",
       "       [-0.53453913, -0.53144295, -0.52818075, ..., -0.39082265,\n",
       "         1.10957424, -0.61881422],\n",
       "       ...,\n",
       "       [ 1.8225737 ,  1.82305502,  1.82410539, ...,  0.13346284,\n",
       "        -1.02893818,  1.82627841],\n",
       "       [ 1.82288198,  1.82351758,  1.82636519, ...,  0.28547491,\n",
       "        -1.00756358,  1.82631595],\n",
       "       [ 1.82493714,  1.83004486,  1.81886679, ...,  0.28421056,\n",
       "        -0.98628412,  1.82628024]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35999b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = test_df.drop([\"date\",\"target\"],axis=1)\n",
    "test_values = test_values.values\n",
    "standard_scaler.fit(test_values)\n",
    "test_values = standard_scaler.transform(test_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e4c8a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_df[\"target\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8768d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 1, ..., 1, 0, 0], dtype=int64), 20373)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels,len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3ae114a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 0, ..., 1, 1, 0], dtype=int64), 5094)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels = test_df[\"target\"].to_numpy()\n",
    "test_labels,len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a472d86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20373,), (20373, 28))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final training data:\n",
    "labels.shape,values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0f6b71",
   "metadata": {},
   "source": [
    "# MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5960cac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 28)]              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                290       \n",
      "                                                                 \n",
      " lambda_9 (Lambda)           (None, 1, 10)             0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 1, 2048)          8478720   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 1, 1024)           12587008  \n",
      "                                                                 \n",
      " lstm_24 (LSTM)              (None, 1, 1024)           8392704   \n",
      "                                                                 \n",
      " global_average_pooling1d_4   (None, 1024)             0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                10250     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,468,983\n",
      "Trainable params: 29,468,983\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model1\n",
    "tf.random.set_seed(42)\n",
    "inputs = tf.keras.layers.Input(shape=28)\n",
    "x = tf.keras.layers.Dense(10,activation=\"relu\")(inputs)\n",
    "x = tf.keras.layers.Lambda(lambda x:tf.expand_dims(x,axis=1))(x)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(1024,return_sequences=True))(x)\n",
    "x = tf.keras.layers.LSTM(1024,return_sequences=True)(x)\n",
    "x = tf.keras.layers.LSTM(1024,return_sequences=True)(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "x = tf.keras.layers.Dense(10,activation=\"relu\")(x)\n",
    "outputs = tf.keras.layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "model1 = tf.keras.models.Model(inputs,outputs)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bb5a2659",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss = \"binary_crossentropy\",optimizer = tf.keras.optimizers.Adam(), metrics = \"accuracy\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3084cefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "637/637 [==============================] - 14s 17ms/step - loss: 0.6938 - accuracy: 0.5097\n",
      "Epoch 2/10\n",
      "637/637 [==============================] - 11s 17ms/step - loss: 0.6932 - accuracy: 0.5101\n",
      "Epoch 3/10\n",
      "637/637 [==============================] - 11s 17ms/step - loss: 0.6930 - accuracy: 0.5108\n",
      "Epoch 4/10\n",
      "637/637 [==============================] - 11s 17ms/step - loss: 0.6928 - accuracy: 0.5121\n",
      "Epoch 5/10\n",
      "637/637 [==============================] - 11s 17ms/step - loss: 0.6931 - accuracy: 0.5126\n",
      "Epoch 6/10\n",
      "637/637 [==============================] - 11s 18ms/step - loss: 0.6929 - accuracy: 0.5136\n",
      "Epoch 7/10\n",
      "637/637 [==============================] - 11s 17ms/step - loss: 0.6924 - accuracy: 0.5136\n",
      "Epoch 8/10\n",
      "637/637 [==============================] - 11s 17ms/step - loss: 0.6924 - accuracy: 0.5163\n",
      "Epoch 9/10\n",
      "637/637 [==============================] - 11s 17ms/step - loss: 0.6923 - accuracy: 0.5155\n",
      "Epoch 10/10\n",
      "637/637 [==============================] - 11s 17ms/step - loss: 0.6921 - accuracy: 0.5194\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit(values,\n",
    "                     labels,\n",
    "                     epochs=10,\n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a5bcb247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 2s 7ms/step - loss: 0.6936 - accuracy: 0.5035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6935892105102539, 0.5035335421562195]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model1.evaluate(test_values,test_labels)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d1a5d4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "249f6483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>SMA_7</th>\n",
       "      <th>SMA_14</th>\n",
       "      <th>SMA_21</th>\n",
       "      <th>RSI_7</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>RSI_21</th>\n",
       "      <th>ATR_14</th>\n",
       "      <th>bb_mavg</th>\n",
       "      <th>bb_hband</th>\n",
       "      <th>bb_lband</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-28 11:45:00+05:30</td>\n",
       "      <td>0.603400</td>\n",
       "      <td>0.603456</td>\n",
       "      <td>0.601087</td>\n",
       "      <td>0.601100</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>0.603192</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.601761</td>\n",
       "      <td>39.141180</td>\n",
       "      <td>45.100563</td>\n",
       "      <td>46.593212</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>0.601946</td>\n",
       "      <td>0.605627</td>\n",
       "      <td>0.598265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-02-28 12:00:00+05:30</td>\n",
       "      <td>0.601100</td>\n",
       "      <td>0.602081</td>\n",
       "      <td>0.600225</td>\n",
       "      <td>0.600575</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>0.602728</td>\n",
       "      <td>0.602515</td>\n",
       "      <td>0.601881</td>\n",
       "      <td>36.414816</td>\n",
       "      <td>43.896867</td>\n",
       "      <td>45.835237</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.602103</td>\n",
       "      <td>0.605225</td>\n",
       "      <td>0.598982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-02-28 12:15:00+05:30</td>\n",
       "      <td>0.600531</td>\n",
       "      <td>0.602038</td>\n",
       "      <td>0.600481</td>\n",
       "      <td>0.601019</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>0.602218</td>\n",
       "      <td>0.602506</td>\n",
       "      <td>0.602052</td>\n",
       "      <td>40.501595</td>\n",
       "      <td>45.227509</td>\n",
       "      <td>46.606126</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>0.602052</td>\n",
       "      <td>0.605209</td>\n",
       "      <td>0.598896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-02-28 12:30:00+05:30</td>\n",
       "      <td>0.601025</td>\n",
       "      <td>0.601269</td>\n",
       "      <td>0.599850</td>\n",
       "      <td>0.601019</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>0.601899</td>\n",
       "      <td>0.602633</td>\n",
       "      <td>0.602003</td>\n",
       "      <td>40.501595</td>\n",
       "      <td>45.227509</td>\n",
       "      <td>46.606126</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.602011</td>\n",
       "      <td>0.605199</td>\n",
       "      <td>0.598823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-02-28 12:45:00+05:30</td>\n",
       "      <td>0.601019</td>\n",
       "      <td>0.601263</td>\n",
       "      <td>0.599725</td>\n",
       "      <td>0.599800</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>0.601454</td>\n",
       "      <td>0.602366</td>\n",
       "      <td>0.601906</td>\n",
       "      <td>32.655532</td>\n",
       "      <td>42.050687</td>\n",
       "      <td>44.680601</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.601857</td>\n",
       "      <td>0.605157</td>\n",
       "      <td>0.598556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10312</th>\n",
       "      <td>10312</td>\n",
       "      <td>2020-11-02 13:45:00+05:30</td>\n",
       "      <td>0.702612</td>\n",
       "      <td>0.705156</td>\n",
       "      <td>0.702037</td>\n",
       "      <td>0.702838</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>0.701772</td>\n",
       "      <td>0.702237</td>\n",
       "      <td>0.701807</td>\n",
       "      <td>57.562220</td>\n",
       "      <td>51.643923</td>\n",
       "      <td>48.979101</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>0.701593</td>\n",
       "      <td>0.706202</td>\n",
       "      <td>0.696984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10313</th>\n",
       "      <td>10313</td>\n",
       "      <td>2020-11-02 14:00:00+05:30</td>\n",
       "      <td>0.702838</td>\n",
       "      <td>0.708244</td>\n",
       "      <td>0.702400</td>\n",
       "      <td>0.706200</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>0.702667</td>\n",
       "      <td>0.702475</td>\n",
       "      <td>0.701812</td>\n",
       "      <td>73.807565</td>\n",
       "      <td>59.775830</td>\n",
       "      <td>54.178170</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>0.701613</td>\n",
       "      <td>0.706296</td>\n",
       "      <td>0.696929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10314</th>\n",
       "      <td>10314</td>\n",
       "      <td>2020-11-02 14:15:00+05:30</td>\n",
       "      <td>0.706100</td>\n",
       "      <td>0.714519</td>\n",
       "      <td>0.706100</td>\n",
       "      <td>0.713462</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>0.704557</td>\n",
       "      <td>0.703301</td>\n",
       "      <td>0.702177</td>\n",
       "      <td>86.667797</td>\n",
       "      <td>71.085792</td>\n",
       "      <td>62.779617</td>\n",
       "      <td>0.004281</td>\n",
       "      <td>0.702185</td>\n",
       "      <td>0.709162</td>\n",
       "      <td>0.695208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10315</th>\n",
       "      <td>10315</td>\n",
       "      <td>2020-11-02 14:30:00+05:30</td>\n",
       "      <td>0.713413</td>\n",
       "      <td>0.715700</td>\n",
       "      <td>0.711888</td>\n",
       "      <td>0.714519</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>0.706422</td>\n",
       "      <td>0.704122</td>\n",
       "      <td>0.702773</td>\n",
       "      <td>87.693093</td>\n",
       "      <td>72.305438</td>\n",
       "      <td>63.816847</td>\n",
       "      <td>0.004247</td>\n",
       "      <td>0.702940</td>\n",
       "      <td>0.711617</td>\n",
       "      <td>0.694263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10316</th>\n",
       "      <td>10316</td>\n",
       "      <td>2020-11-02 14:45:00+05:30</td>\n",
       "      <td>0.714431</td>\n",
       "      <td>0.714463</td>\n",
       "      <td>0.711987</td>\n",
       "      <td>0.713556</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>0.707992</td>\n",
       "      <td>0.704792</td>\n",
       "      <td>0.703446</td>\n",
       "      <td>81.065382</td>\n",
       "      <td>69.431371</td>\n",
       "      <td>62.159456</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>0.703805</td>\n",
       "      <td>0.713074</td>\n",
       "      <td>0.694537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10317 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id                       date      open      high       low  \\\n",
       "0          0  2019-02-28 11:45:00+05:30  0.603400  0.603456  0.601087   \n",
       "1          1  2019-02-28 12:00:00+05:30  0.601100  0.602081  0.600225   \n",
       "2          2  2019-02-28 12:15:00+05:30  0.600531  0.602038  0.600481   \n",
       "3          3  2019-02-28 12:30:00+05:30  0.601025  0.601269  0.599850   \n",
       "4          4  2019-02-28 12:45:00+05:30  0.601019  0.601263  0.599725   \n",
       "...      ...                        ...       ...       ...       ...   \n",
       "10312  10312  2020-11-02 13:45:00+05:30  0.702612  0.705156  0.702037   \n",
       "10313  10313  2020-11-02 14:00:00+05:30  0.702838  0.708244  0.702400   \n",
       "10314  10314  2020-11-02 14:15:00+05:30  0.706100  0.714519  0.706100   \n",
       "10315  10315  2020-11-02 14:30:00+05:30  0.713413  0.715700  0.711888   \n",
       "10316  10316  2020-11-02 14:45:00+05:30  0.714431  0.714463  0.711987   \n",
       "\n",
       "          close  day  week     SMA_7    SMA_14    SMA_21      RSI_7  \\\n",
       "0      0.601100   28     9  0.603192  0.602410  0.601761  39.141180   \n",
       "1      0.600575   28     9  0.602728  0.602515  0.601881  36.414816   \n",
       "2      0.601019   28     9  0.602218  0.602506  0.602052  40.501595   \n",
       "3      0.601019   28     9  0.601899  0.602633  0.602003  40.501595   \n",
       "4      0.599800   28     9  0.601454  0.602366  0.601906  32.655532   \n",
       "...         ...  ...   ...       ...       ...       ...        ...   \n",
       "10312  0.702838    2    45  0.701772  0.702237  0.701807  57.562220   \n",
       "10313  0.706200    2    45  0.702667  0.702475  0.701812  73.807565   \n",
       "10314  0.713462    2    45  0.704557  0.703301  0.702177  86.667797   \n",
       "10315  0.714519    2    45  0.706422  0.704122  0.702773  87.693093   \n",
       "10316  0.713556    2    45  0.707992  0.704792  0.703446  81.065382   \n",
       "\n",
       "          RSI_14     RSI_21    ATR_14   bb_mavg  bb_hband  bb_lband  \n",
       "0      45.100563  46.593212  0.002758  0.601946  0.605627  0.598265  \n",
       "1      43.896867  45.835237  0.002694  0.602103  0.605225  0.598982  \n",
       "2      45.227509  46.606126  0.002613  0.602052  0.605209  0.598896  \n",
       "3      45.227509  46.606126  0.002527  0.602011  0.605199  0.598823  \n",
       "4      42.050687  44.680601  0.002457  0.601857  0.605157  0.598556  \n",
       "...          ...        ...       ...       ...       ...       ...  \n",
       "10312  51.643923  48.979101  0.003817  0.701593  0.706202  0.696984  \n",
       "10313  59.775830  54.178170  0.003962  0.701613  0.706296  0.696929  \n",
       "10314  71.085792  62.779617  0.004281  0.702185  0.709162  0.695208  \n",
       "10315  72.305438  63.816847  0.004247  0.702940  0.711617  0.694263  \n",
       "10316  69.431371  62.159456  0.004125  0.703805  0.713074  0.694537  \n",
       "\n",
       "[10317 rows x 18 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594c0675",
   "metadata": {},
   "source": [
    "# PREPARING DATA FOR MODEL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed7d84ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>day</th>\n",
       "      <th>SMA_7</th>\n",
       "      <th>SMA_14</th>\n",
       "      <th>SMA_21</th>\n",
       "      <th>RSI_7</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>RSI_21</th>\n",
       "      <th>ATR_14</th>\n",
       "      <th>bb_mavg</th>\n",
       "      <th>bb_hband</th>\n",
       "      <th>bb_lband</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.252483</td>\n",
       "      <td>0.249671</td>\n",
       "      <td>0.255665</td>\n",
       "      <td>0.250255</td>\n",
       "      <td>12</td>\n",
       "      <td>0.249131</td>\n",
       "      <td>0.246873</td>\n",
       "      <td>0.247927</td>\n",
       "      <td>54.402627</td>\n",
       "      <td>48.236033</td>\n",
       "      <td>45.263488</td>\n",
       "      <td>0.007017</td>\n",
       "      <td>0.247667</td>\n",
       "      <td>0.256181</td>\n",
       "      <td>0.239153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.247851</td>\n",
       "      <td>0.246028</td>\n",
       "      <td>0.257602</td>\n",
       "      <td>0.251258</td>\n",
       "      <td>12</td>\n",
       "      <td>0.250327</td>\n",
       "      <td>0.247607</td>\n",
       "      <td>0.247838</td>\n",
       "      <td>57.307707</td>\n",
       "      <td>49.928940</td>\n",
       "      <td>46.453986</td>\n",
       "      <td>0.007040</td>\n",
       "      <td>0.247534</td>\n",
       "      <td>0.255730</td>\n",
       "      <td>0.239338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.248817</td>\n",
       "      <td>0.248992</td>\n",
       "      <td>0.259178</td>\n",
       "      <td>0.253956</td>\n",
       "      <td>12</td>\n",
       "      <td>0.251520</td>\n",
       "      <td>0.248550</td>\n",
       "      <td>0.247840</td>\n",
       "      <td>64.423555</td>\n",
       "      <td>54.263566</td>\n",
       "      <td>49.554022</td>\n",
       "      <td>0.007103</td>\n",
       "      <td>0.247566</td>\n",
       "      <td>0.255858</td>\n",
       "      <td>0.239275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.251481</td>\n",
       "      <td>0.249916</td>\n",
       "      <td>0.260682</td>\n",
       "      <td>0.253628</td>\n",
       "      <td>12</td>\n",
       "      <td>0.252341</td>\n",
       "      <td>0.248788</td>\n",
       "      <td>0.247855</td>\n",
       "      <td>62.935127</td>\n",
       "      <td>53.655190</td>\n",
       "      <td>49.190342</td>\n",
       "      <td>0.007076</td>\n",
       "      <td>0.247743</td>\n",
       "      <td>0.256385</td>\n",
       "      <td>0.239101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.251066</td>\n",
       "      <td>0.250750</td>\n",
       "      <td>0.262421</td>\n",
       "      <td>0.255314</td>\n",
       "      <td>12</td>\n",
       "      <td>0.253037</td>\n",
       "      <td>0.249406</td>\n",
       "      <td>0.248103</td>\n",
       "      <td>67.444567</td>\n",
       "      <td>56.362731</td>\n",
       "      <td>51.125779</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>0.248086</td>\n",
       "      <td>0.257337</td>\n",
       "      <td>0.238835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25495</th>\n",
       "      <td>0.711045</td>\n",
       "      <td>0.711635</td>\n",
       "      <td>0.721231</td>\n",
       "      <td>0.718972</td>\n",
       "      <td>28</td>\n",
       "      <td>0.716356</td>\n",
       "      <td>0.715153</td>\n",
       "      <td>0.713530</td>\n",
       "      <td>61.663695</td>\n",
       "      <td>53.338774</td>\n",
       "      <td>51.661272</td>\n",
       "      <td>0.006446</td>\n",
       "      <td>0.713322</td>\n",
       "      <td>0.720650</td>\n",
       "      <td>0.705994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25496</th>\n",
       "      <td>0.712138</td>\n",
       "      <td>0.712070</td>\n",
       "      <td>0.720268</td>\n",
       "      <td>0.717022</td>\n",
       "      <td>28</td>\n",
       "      <td>0.717192</td>\n",
       "      <td>0.715279</td>\n",
       "      <td>0.713498</td>\n",
       "      <td>53.363878</td>\n",
       "      <td>50.340798</td>\n",
       "      <td>49.789358</td>\n",
       "      <td>0.006478</td>\n",
       "      <td>0.713906</td>\n",
       "      <td>0.720413</td>\n",
       "      <td>0.707398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25497</th>\n",
       "      <td>0.710287</td>\n",
       "      <td>0.710058</td>\n",
       "      <td>0.719988</td>\n",
       "      <td>0.716538</td>\n",
       "      <td>28</td>\n",
       "      <td>0.717063</td>\n",
       "      <td>0.715391</td>\n",
       "      <td>0.714031</td>\n",
       "      <td>51.366201</td>\n",
       "      <td>49.597282</td>\n",
       "      <td>49.324591</td>\n",
       "      <td>0.006513</td>\n",
       "      <td>0.714128</td>\n",
       "      <td>0.720676</td>\n",
       "      <td>0.707579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25498</th>\n",
       "      <td>0.709853</td>\n",
       "      <td>0.709922</td>\n",
       "      <td>0.719988</td>\n",
       "      <td>0.717085</td>\n",
       "      <td>28</td>\n",
       "      <td>0.717277</td>\n",
       "      <td>0.715434</td>\n",
       "      <td>0.714268</td>\n",
       "      <td>53.657489</td>\n",
       "      <td>50.488807</td>\n",
       "      <td>49.880711</td>\n",
       "      <td>0.006520</td>\n",
       "      <td>0.714450</td>\n",
       "      <td>0.720914</td>\n",
       "      <td>0.707985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25499</th>\n",
       "      <td>0.710359</td>\n",
       "      <td>0.710022</td>\n",
       "      <td>0.720232</td>\n",
       "      <td>0.717195</td>\n",
       "      <td>28</td>\n",
       "      <td>0.717317</td>\n",
       "      <td>0.715599</td>\n",
       "      <td>0.714580</td>\n",
       "      <td>54.161395</td>\n",
       "      <td>50.676715</td>\n",
       "      <td>49.995949</td>\n",
       "      <td>0.006559</td>\n",
       "      <td>0.714898</td>\n",
       "      <td>0.720792</td>\n",
       "      <td>0.709004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25500 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           open      high       low     close  day     SMA_7    SMA_14  \\\n",
       "0      0.252483  0.249671  0.255665  0.250255   12  0.249131  0.246873   \n",
       "1      0.247851  0.246028  0.257602  0.251258   12  0.250327  0.247607   \n",
       "2      0.248817  0.248992  0.259178  0.253956   12  0.251520  0.248550   \n",
       "3      0.251481  0.249916  0.260682  0.253628   12  0.252341  0.248788   \n",
       "4      0.251066  0.250750  0.262421  0.255314   12  0.253037  0.249406   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "25495  0.711045  0.711635  0.721231  0.718972   28  0.716356  0.715153   \n",
       "25496  0.712138  0.712070  0.720268  0.717022   28  0.717192  0.715279   \n",
       "25497  0.710287  0.710058  0.719988  0.716538   28  0.717063  0.715391   \n",
       "25498  0.709853  0.709922  0.719988  0.717085   28  0.717277  0.715434   \n",
       "25499  0.710359  0.710022  0.720232  0.717195   28  0.717317  0.715599   \n",
       "\n",
       "         SMA_21      RSI_7     RSI_14     RSI_21    ATR_14   bb_mavg  \\\n",
       "0      0.247927  54.402627  48.236033  45.263488  0.007017  0.247667   \n",
       "1      0.247838  57.307707  49.928940  46.453986  0.007040  0.247534   \n",
       "2      0.247840  64.423555  54.263566  49.554022  0.007103  0.247566   \n",
       "3      0.247855  62.935127  53.655190  49.190342  0.007076  0.247743   \n",
       "4      0.248103  67.444567  56.362731  51.125779  0.007199  0.248086   \n",
       "...         ...        ...        ...        ...       ...       ...   \n",
       "25495  0.713530  61.663695  53.338774  51.661272  0.006446  0.713322   \n",
       "25496  0.713498  53.363878  50.340798  49.789358  0.006478  0.713906   \n",
       "25497  0.714031  51.366201  49.597282  49.324591  0.006513  0.714128   \n",
       "25498  0.714268  53.657489  50.488807  49.880711  0.006520  0.714450   \n",
       "25499  0.714580  54.161395  50.676715  49.995949  0.006559  0.714898   \n",
       "\n",
       "       bb_hband  bb_lband  \n",
       "0      0.256181  0.239153  \n",
       "1      0.255730  0.239338  \n",
       "2      0.255858  0.239275  \n",
       "3      0.256385  0.239101  \n",
       "4      0.257337  0.238835  \n",
       "...         ...       ...  \n",
       "25495  0.720650  0.705994  \n",
       "25496  0.720413  0.707398  \n",
       "25497  0.720676  0.707579  \n",
       "25498  0.720914  0.707985  \n",
       "25499  0.720792  0.709004  \n",
       "\n",
       "[25500 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"train_data.csv\")\n",
    "train.drop([\"week\",\"Id\",\"date\"],axis=1,inplace=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1c211ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2524832 , 0.24967144, 0.25566544, ..., 0.24766699, 0.25618067,\n",
       "        0.23915331],\n",
       "       [0.2478509 , 0.24602779, 0.25760196, ..., 0.24753391, 0.25572977,\n",
       "        0.23933805],\n",
       "       [0.24881709, 0.24899165, 0.2591782 , ..., 0.24756627, 0.25585762,\n",
       "        0.23927491],\n",
       "       ...,\n",
       "       [0.71028679, 0.7100581 , 0.71998847, ..., 0.7141275 , 0.72067604,\n",
       "        0.70757896],\n",
       "       [0.70985336, 0.70992214, 0.71998847, ..., 0.71444972, 0.72091398,\n",
       "        0.70798546],\n",
       "       [0.71035903, 0.71002184, 0.72023166, ..., 0.71489818, 0.72079233,\n",
       "        0.70900404]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = train.values\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "404626a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.8058208 , -0.81198957, -0.83730458, ..., -0.83856587,\n",
       "        -0.83574818, -0.84082774],\n",
       "       [-0.82729714, -0.82881621, -0.82830192, ..., -0.83917739,\n",
       "        -0.83781824, -0.83997861],\n",
       "       [-0.82281767, -0.81512887, -0.82097417, ..., -0.8390287 ,\n",
       "        -0.83723126, -0.84026882],\n",
       "       ...,\n",
       "       [ 1.31665197,  1.31411156,  1.32128197, ...,  1.30487908,\n",
       "         1.29671032,  1.31218737],\n",
       "       [ 1.31464248,  1.3134837 ,  1.32128197, ...,  1.30635972,\n",
       "         1.29780268,  1.31405575],\n",
       "       [ 1.31698688,  1.31394413,  1.32241254, ...,  1.30842046,\n",
       "         1.29724419,  1.31873742]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "s = StandardScaler()\n",
    "s.fit(values)\n",
    "values = s.transform(values)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0767aa16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.read_csv(\"train_target.csv\")\n",
    "target.drop([\"Id\"],axis = 1,inplace=True)\n",
    "labels = target.values\n",
    "labels = tf.squeeze(labels).numpy()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e3e4c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25500, 15), 25500)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.shape,len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "742e5315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train,test,labels,test_labels = train_test_split(values,labels,test_size=0.2,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0ea97ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 15)]              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                160       \n",
      "                                                                 \n",
      " lambda_1 (Lambda)           (None, 1, 10)             0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 1, 2048)          8478720   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 1, 1024)           12587008  \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 1, 1024)           8392704   \n",
      "                                                                 \n",
      " global_average_pooling1d_1   (None, 1024)             0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                10250     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,468,853\n",
      "Trainable params: 29,468,853\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "inputs = tf.keras.layers.Input(shape=15)\n",
    "x = tf.keras.layers.Dense(10,activation=\"relu\")(inputs)\n",
    "x = tf.keras.layers.Lambda(lambda x:tf.expand_dims(x,axis=1))(x)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(1024,return_sequences=True))(x)\n",
    "x = tf.keras.layers.LSTM(1024,return_sequences=True)(x)\n",
    "x = tf.keras.layers.LSTM(1024,return_sequences=True)(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "x = tf.keras.layers.Dense(10,activation=\"relu\")(x)\n",
    "outputs = tf.keras.layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "model1 = tf.keras.models.Model(inputs,outputs)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8653e88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss = \"binary_crossentropy\",optimizer = tf.keras.optimizers.Adam(), metrics = \"accuracy\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ac404a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "638/638 [==============================] - 12s 19ms/step - loss: 0.6919 - accuracy: 0.5216\n",
      "Epoch 2/50\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.6920 - accuracy: 0.5219\n",
      "Epoch 3/50\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.6917 - accuracy: 0.5209\n",
      "Epoch 4/50\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.6918 - accuracy: 0.5190\n",
      "Epoch 5/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6917 - accuracy: 0.5235\n",
      "Epoch 6/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6917 - accuracy: 0.5246\n",
      "Epoch 7/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6917 - accuracy: 0.5205\n",
      "Epoch 8/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6920 - accuracy: 0.5190\n",
      "Epoch 9/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6916 - accuracy: 0.5238\n",
      "Epoch 10/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6920 - accuracy: 0.5191\n",
      "Epoch 11/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6918 - accuracy: 0.5186\n",
      "Epoch 12/50\n",
      "638/638 [==============================] - 11s 16ms/step - loss: 0.6918 - accuracy: 0.5208\n",
      "Epoch 13/50\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.6918 - accuracy: 0.5217\n",
      "Epoch 14/50\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.6914 - accuracy: 0.5250\n",
      "Epoch 15/50\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.6918 - accuracy: 0.5195\n",
      "Epoch 16/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6916 - accuracy: 0.5204\n",
      "Epoch 17/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6917 - accuracy: 0.5185\n",
      "Epoch 18/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6916 - accuracy: 0.5236\n",
      "Epoch 19/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6914 - accuracy: 0.5244\n",
      "Epoch 20/50\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.6918 - accuracy: 0.5214\n",
      "Epoch 21/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6917 - accuracy: 0.5181\n",
      "Epoch 22/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6916 - accuracy: 0.5181\n",
      "Epoch 23/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6915 - accuracy: 0.5205\n",
      "Epoch 24/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6916 - accuracy: 0.5180\n",
      "Epoch 25/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6912 - accuracy: 0.5183\n",
      "Epoch 26/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6913 - accuracy: 0.5227\n",
      "Epoch 27/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6912 - accuracy: 0.5219\n",
      "Epoch 28/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6912 - accuracy: 0.5203\n",
      "Epoch 29/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6915 - accuracy: 0.5209\n",
      "Epoch 30/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6915 - accuracy: 0.5214\n",
      "Epoch 31/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6913 - accuracy: 0.5194\n",
      "Epoch 32/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6914 - accuracy: 0.5208\n",
      "Epoch 33/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6914 - accuracy: 0.5255\n",
      "Epoch 34/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6911 - accuracy: 0.5229\n",
      "Epoch 35/50\n",
      "638/638 [==============================] - 11s 16ms/step - loss: 0.6910 - accuracy: 0.5246\n",
      "Epoch 36/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6912 - accuracy: 0.5226\n",
      "Epoch 37/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6909 - accuracy: 0.5204\n",
      "Epoch 38/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6910 - accuracy: 0.5242\n",
      "Epoch 39/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6914 - accuracy: 0.5214\n",
      "Epoch 40/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6913 - accuracy: 0.5208\n",
      "Epoch 41/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6911 - accuracy: 0.5194\n",
      "Epoch 42/50\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 0.6914 - accuracy: 0.5232\n",
      "Epoch 43/50\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.6914 - accuracy: 0.5200\n",
      "Epoch 44/50\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.6913 - accuracy: 0.5210\n",
      "Epoch 45/50\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.6911 - accuracy: 0.5206\n",
      "Epoch 46/50\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.6911 - accuracy: 0.5208\n",
      "Epoch 47/50\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.6911 - accuracy: 0.5215\n",
      "Epoch 48/50\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.6909 - accuracy: 0.5256\n",
      "Epoch 49/50\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.6909 - accuracy: 0.5243\n",
      "Epoch 50/50\n",
      "638/638 [==============================] - 11s 16ms/step - loss: 0.6907 - accuracy: 0.5287\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit(train,\n",
    "                     labels,\n",
    "                     epochs=50,\n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "40f60bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6034    , 0.60345625, 0.6010875 , ..., 0.60194594, 0.60562733,\n",
       "        0.59826455],\n",
       "       [0.6011    , 0.60208125, 0.600225  , ..., 0.60210344, 0.60522458,\n",
       "        0.59898229],\n",
       "       [0.60053125, 0.6020375 , 0.60048125, ..., 0.6020525 , 0.60520933,\n",
       "        0.59889567],\n",
       "       ...,\n",
       "       [0.7061    , 0.71451875, 0.7061    , ..., 0.70218531, 0.70916219,\n",
       "        0.69520843],\n",
       "       [0.7134125 , 0.7157    , 0.7118875 , ..., 0.70294031, 0.71161722,\n",
       "        0.69426341],\n",
       "       [0.71443125, 0.7144625 , 0.7119875 , ..., 0.70380531, 0.71307354,\n",
       "        0.69453708]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test_data.csv\")\n",
    "test.drop([\"week\",\"Id\",\"date\"],axis=1,inplace=True)\n",
    "values = test.values\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "357be33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.34844132, -0.36345368, -0.35066206, ..., -0.35978134,\n",
       "        -0.42771608, -0.2952659 ],\n",
       "       [-0.3673442 , -0.37481868, -0.35771096, ..., -0.35848433,\n",
       "        -0.4311619 , -0.28959746],\n",
       "       [-0.37201856, -0.3751803 , -0.35561672, ..., -0.35890379,\n",
       "        -0.43129235, -0.29028161],\n",
       "       ...,\n",
       "       [ 0.49561377,  0.55452893,  0.50756606, ...,  0.46568975,\n",
       "         0.45810483,  0.47035188],\n",
       "       [ 0.55571263,  0.5642925 ,  0.55486515, ...,  0.47190718,\n",
       "         0.47910949,  0.4628885 ],\n",
       "       [ 0.56408538,  0.55406399,  0.55568241, ...,  0.47903045,\n",
       "         0.49156947,  0.46504986]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.fit(values)\n",
    "values = s.transform(values)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d7f11a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model1.predict(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6fac07fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tf.round(pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e03f3283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 1, ..., 1, 1, 1], dtype=int64), (10317,))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = tf.squeeze(pred).numpy()\n",
    "pred = tf.cast(pred,dtype = tf.int64).numpy()\n",
    "pred,pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dfc4f5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     1,     2, ..., 10314, 10315, 10316]), (10317,))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = np.arange(0,len(values))\n",
    "l,l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "773da97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(list(zip(l, pred)),\n",
    "               columns =['Id', 'target'])\n",
    "pred_df.to_csv(\"submission3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7ab6052a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>day</th>\n",
       "      <th>SMA_7</th>\n",
       "      <th>SMA_14</th>\n",
       "      <th>SMA_21</th>\n",
       "      <th>RSI_7</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>RSI_21</th>\n",
       "      <th>ATR_14</th>\n",
       "      <th>bb_mavg</th>\n",
       "      <th>bb_hband</th>\n",
       "      <th>bb_lband</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.603400</td>\n",
       "      <td>0.603456</td>\n",
       "      <td>0.601087</td>\n",
       "      <td>0.601100</td>\n",
       "      <td>28</td>\n",
       "      <td>0.603192</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.601761</td>\n",
       "      <td>39.141180</td>\n",
       "      <td>45.100563</td>\n",
       "      <td>46.593212</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>0.601946</td>\n",
       "      <td>0.605627</td>\n",
       "      <td>0.598265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.601100</td>\n",
       "      <td>0.602081</td>\n",
       "      <td>0.600225</td>\n",
       "      <td>0.600575</td>\n",
       "      <td>28</td>\n",
       "      <td>0.602728</td>\n",
       "      <td>0.602515</td>\n",
       "      <td>0.601881</td>\n",
       "      <td>36.414816</td>\n",
       "      <td>43.896867</td>\n",
       "      <td>45.835237</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.602103</td>\n",
       "      <td>0.605225</td>\n",
       "      <td>0.598982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.600531</td>\n",
       "      <td>0.602038</td>\n",
       "      <td>0.600481</td>\n",
       "      <td>0.601019</td>\n",
       "      <td>28</td>\n",
       "      <td>0.602218</td>\n",
       "      <td>0.602506</td>\n",
       "      <td>0.602052</td>\n",
       "      <td>40.501595</td>\n",
       "      <td>45.227509</td>\n",
       "      <td>46.606126</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>0.602052</td>\n",
       "      <td>0.605209</td>\n",
       "      <td>0.598896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.601025</td>\n",
       "      <td>0.601269</td>\n",
       "      <td>0.599850</td>\n",
       "      <td>0.601019</td>\n",
       "      <td>28</td>\n",
       "      <td>0.601899</td>\n",
       "      <td>0.602633</td>\n",
       "      <td>0.602003</td>\n",
       "      <td>40.501595</td>\n",
       "      <td>45.227509</td>\n",
       "      <td>46.606126</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.602011</td>\n",
       "      <td>0.605199</td>\n",
       "      <td>0.598823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.601019</td>\n",
       "      <td>0.601263</td>\n",
       "      <td>0.599725</td>\n",
       "      <td>0.599800</td>\n",
       "      <td>28</td>\n",
       "      <td>0.601454</td>\n",
       "      <td>0.602366</td>\n",
       "      <td>0.601906</td>\n",
       "      <td>32.655532</td>\n",
       "      <td>42.050687</td>\n",
       "      <td>44.680601</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.601857</td>\n",
       "      <td>0.605157</td>\n",
       "      <td>0.598556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10312</th>\n",
       "      <td>0.702612</td>\n",
       "      <td>0.705156</td>\n",
       "      <td>0.702037</td>\n",
       "      <td>0.702838</td>\n",
       "      <td>2</td>\n",
       "      <td>0.701772</td>\n",
       "      <td>0.702237</td>\n",
       "      <td>0.701807</td>\n",
       "      <td>57.562220</td>\n",
       "      <td>51.643923</td>\n",
       "      <td>48.979101</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>0.701593</td>\n",
       "      <td>0.706202</td>\n",
       "      <td>0.696984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10313</th>\n",
       "      <td>0.702838</td>\n",
       "      <td>0.708244</td>\n",
       "      <td>0.702400</td>\n",
       "      <td>0.706200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.702667</td>\n",
       "      <td>0.702475</td>\n",
       "      <td>0.701812</td>\n",
       "      <td>73.807565</td>\n",
       "      <td>59.775830</td>\n",
       "      <td>54.178170</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>0.701613</td>\n",
       "      <td>0.706296</td>\n",
       "      <td>0.696929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10314</th>\n",
       "      <td>0.706100</td>\n",
       "      <td>0.714519</td>\n",
       "      <td>0.706100</td>\n",
       "      <td>0.713462</td>\n",
       "      <td>2</td>\n",
       "      <td>0.704557</td>\n",
       "      <td>0.703301</td>\n",
       "      <td>0.702177</td>\n",
       "      <td>86.667797</td>\n",
       "      <td>71.085792</td>\n",
       "      <td>62.779617</td>\n",
       "      <td>0.004281</td>\n",
       "      <td>0.702185</td>\n",
       "      <td>0.709162</td>\n",
       "      <td>0.695208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10315</th>\n",
       "      <td>0.713413</td>\n",
       "      <td>0.715700</td>\n",
       "      <td>0.711888</td>\n",
       "      <td>0.714519</td>\n",
       "      <td>2</td>\n",
       "      <td>0.706422</td>\n",
       "      <td>0.704122</td>\n",
       "      <td>0.702773</td>\n",
       "      <td>87.693093</td>\n",
       "      <td>72.305438</td>\n",
       "      <td>63.816847</td>\n",
       "      <td>0.004247</td>\n",
       "      <td>0.702940</td>\n",
       "      <td>0.711617</td>\n",
       "      <td>0.694263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10316</th>\n",
       "      <td>0.714431</td>\n",
       "      <td>0.714463</td>\n",
       "      <td>0.711987</td>\n",
       "      <td>0.713556</td>\n",
       "      <td>2</td>\n",
       "      <td>0.707992</td>\n",
       "      <td>0.704792</td>\n",
       "      <td>0.703446</td>\n",
       "      <td>81.065382</td>\n",
       "      <td>69.431371</td>\n",
       "      <td>62.159456</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>0.703805</td>\n",
       "      <td>0.713074</td>\n",
       "      <td>0.694537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10317 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           open      high       low     close  day     SMA_7    SMA_14  \\\n",
       "0      0.603400  0.603456  0.601087  0.601100   28  0.603192  0.602410   \n",
       "1      0.601100  0.602081  0.600225  0.600575   28  0.602728  0.602515   \n",
       "2      0.600531  0.602038  0.600481  0.601019   28  0.602218  0.602506   \n",
       "3      0.601025  0.601269  0.599850  0.601019   28  0.601899  0.602633   \n",
       "4      0.601019  0.601263  0.599725  0.599800   28  0.601454  0.602366   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "10312  0.702612  0.705156  0.702037  0.702838    2  0.701772  0.702237   \n",
       "10313  0.702838  0.708244  0.702400  0.706200    2  0.702667  0.702475   \n",
       "10314  0.706100  0.714519  0.706100  0.713462    2  0.704557  0.703301   \n",
       "10315  0.713413  0.715700  0.711888  0.714519    2  0.706422  0.704122   \n",
       "10316  0.714431  0.714463  0.711987  0.713556    2  0.707992  0.704792   \n",
       "\n",
       "         SMA_21      RSI_7     RSI_14     RSI_21    ATR_14   bb_mavg  \\\n",
       "0      0.601761  39.141180  45.100563  46.593212  0.002758  0.601946   \n",
       "1      0.601881  36.414816  43.896867  45.835237  0.002694  0.602103   \n",
       "2      0.602052  40.501595  45.227509  46.606126  0.002613  0.602052   \n",
       "3      0.602003  40.501595  45.227509  46.606126  0.002527  0.602011   \n",
       "4      0.601906  32.655532  42.050687  44.680601  0.002457  0.601857   \n",
       "...         ...        ...        ...        ...       ...       ...   \n",
       "10312  0.701807  57.562220  51.643923  48.979101  0.003817  0.701593   \n",
       "10313  0.701812  73.807565  59.775830  54.178170  0.003962  0.701613   \n",
       "10314  0.702177  86.667797  71.085792  62.779617  0.004281  0.702185   \n",
       "10315  0.702773  87.693093  72.305438  63.816847  0.004247  0.702940   \n",
       "10316  0.703446  81.065382  69.431371  62.159456  0.004125  0.703805   \n",
       "\n",
       "       bb_hband  bb_lband  \n",
       "0      0.605627  0.598265  \n",
       "1      0.605225  0.598982  \n",
       "2      0.605209  0.598896  \n",
       "3      0.605199  0.598823  \n",
       "4      0.605157  0.598556  \n",
       "...         ...       ...  \n",
       "10312  0.706202  0.696984  \n",
       "10313  0.706296  0.696929  \n",
       "10314  0.709162  0.695208  \n",
       "10315  0.711617  0.694263  \n",
       "10316  0.713074  0.694537  \n",
       "\n",
       "[10317 rows x 15 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dce2ea0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.8058208 , -0.81198957, -0.83730458, ..., -0.83856587,\n",
       "        -0.83574818, -0.84082774],\n",
       "       [-0.82729714, -0.82881621, -0.82830192, ..., -0.83917739,\n",
       "        -0.83781824, -0.83997861],\n",
       "       [-0.82281767, -0.81512887, -0.82097417, ..., -0.8390287 ,\n",
       "        -0.83723126, -0.84026882],\n",
       "       ...,\n",
       "       [ 1.14463199,  1.14304066,  1.14972896, ...,  1.17838829,\n",
       "         1.18672715,  1.169254  ],\n",
       "       [ 1.14919519,  1.14915183,  1.15513056, ...,  1.17562388,\n",
       "         1.18320826,  1.16724679],\n",
       "       [ 1.15040925,  1.14902625,  1.15471183, ...,  1.17297674,\n",
       "         1.17949467,  1.16566912]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f540a882",
   "metadata": {},
   "source": [
    "# BIDIRECTIONAL LSTMS MODEL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f01a632a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 15)]              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 27)                432       \n",
      "                                                                 \n",
      " lambda_2 (Lambda)           (None, 1, 27)             0         \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 1, 2048)          8617984   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 1, 2048)          25174016  \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 1, 2048)          25174016  \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " global_average_pooling1d_2   (None, 2048)             0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 36)                73764     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 37        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59,040,249\n",
      "Trainable params: 59,040,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "inputs = tf.keras.layers.Input(shape=15)\n",
    "x = tf.keras.layers.Dense(27,activation=\"relu\")(inputs)\n",
    "x = tf.keras.layers.Lambda(lambda x:tf.expand_dims(x,axis=1))(x)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(1024,return_sequences=True))(x)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(1024,return_sequences=True))(x)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(1024,return_sequences=True))(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "x = tf.keras.layers.Dense(36,activation=\"relu\")(x)\n",
    "outputs = tf.keras.layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "model2 = tf.keras.models.Model(inputs,outputs)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0bb18e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss = \"binary_crossentropy\",optimizer = tf.keras.optimizers.Adam(), metrics = \"accuracy\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "299b6ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "638/638 [==============================] - 22s 29ms/step - loss: 0.6943 - accuracy: 0.5038\n",
      "Epoch 2/50\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.6935 - accuracy: 0.5105\n",
      "Epoch 3/50\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.6935 - accuracy: 0.5092\n",
      "Epoch 4/50\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.6929 - accuracy: 0.5112\n",
      "Epoch 5/50\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.6929 - accuracy: 0.5104\n",
      "Epoch 6/50\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.6927 - accuracy: 0.5129\n",
      "Epoch 7/50\n",
      "638/638 [==============================] - 19s 29ms/step - loss: 0.6929 - accuracy: 0.5093\n",
      "Epoch 8/50\n",
      "638/638 [==============================] - 19s 29ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 9/50\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 10/50\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 11/50\n",
      "638/638 [==============================] - 19s 29ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 12/50\n",
      "638/638 [==============================] - 19s 29ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 13/50\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.6929 - accuracy: 0.51110s - loss: 0.6930 - accura\n",
      "Epoch 14/50\n",
      "638/638 [==============================] - 19s 29ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 15/50\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 16/50\n",
      "638/638 [==============================] - 18s 28ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 17/50\n",
      "638/638 [==============================] - 18s 28ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 18/50\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 19/50\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 20/50\n",
      "638/638 [==============================] - 18s 28ms/step - loss: 0.6930 - accuracy: 0.5111\n",
      "Epoch 21/50\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 22/50\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 23/50\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 24/50\n",
      "638/638 [==============================] - 19s 29ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 25/50\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 26/50\n",
      "638/638 [==============================] - 19s 29ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 27/50\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 28/50\n",
      "638/638 [==============================] - 19s 29ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 29/50\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 30/50\n",
      "638/638 [==============================] - 18s 28ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 31/50\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 32/50\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 33/50\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 34/50\n",
      "101/638 [===>..........................] - ETA: 15s - loss: 0.6933 - accuracy: 0.5009"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HARSHV~1\\AppData\\Local\\Temp/ipykernel_2480/2015561175.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history2 = model2.fit(train,\n\u001b[0m\u001b[0;32m      2\u001b[0m                      \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                      \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     batch_size=32)\n",
      "\u001b[1;32mc:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(train,\n",
    "                     labels,\n",
    "                     epochs=50,\n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "882d0743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM,Dropout,Dense,Input \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras import optimizers\n",
    "inputs = Input(shape=16)\n",
    "x = Dense(20,activation=\"relu\")(inputs)\n",
    "x = tf.keras.layers.Lambda(lambda x:tf.expand_dims(x,axis=1))(x)\n",
    "x = LSTM(25,return_sequences=False)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "outputs = Dense(1,activation='sigmoid')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(),\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d073fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25500, 16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train_data.csv\")\n",
    "train.drop([\"Id\",\"date\"],axis=1,inplace=True)\n",
    "train = train.values\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f615ca72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.read_csv(\"train_target.csv\")\n",
    "labels = target[\"target\"].to_numpy()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87b5b8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "797/797 [==============================] - 12s 6ms/step - loss: 0.6953 - accuracy: 0.5074\n",
      "Epoch 2/20\n",
      "797/797 [==============================] - 5s 6ms/step - loss: 0.6946 - accuracy: 0.5060\n",
      "Epoch 3/20\n",
      "797/797 [==============================] - 4s 6ms/step - loss: 0.6939 - accuracy: 0.5020\n",
      "Epoch 4/20\n",
      "797/797 [==============================] - 4s 5ms/step - loss: 0.6933 - accuracy: 0.5091\n",
      "Epoch 5/20\n",
      "797/797 [==============================] - 5s 6ms/step - loss: 0.6930 - accuracy: 0.5103\n",
      "Epoch 6/20\n",
      "797/797 [==============================] - 5s 6ms/step - loss: 0.6932 - accuracy: 0.5085\n",
      "Epoch 7/20\n",
      "797/797 [==============================] - 5s 6ms/step - loss: 0.6928 - accuracy: 0.5152\n",
      "Epoch 8/20\n",
      "797/797 [==============================] - 4s 5ms/step - loss: 0.6929 - accuracy: 0.5134\n",
      "Epoch 9/20\n",
      "797/797 [==============================] - 5s 6ms/step - loss: 0.6929 - accuracy: 0.5164\n",
      "Epoch 10/20\n",
      "797/797 [==============================] - 5s 6ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 11/20\n",
      "797/797 [==============================] - 5s 6ms/step - loss: 0.6928 - accuracy: 0.5159\n",
      "Epoch 12/20\n",
      "797/797 [==============================] - 4s 6ms/step - loss: 0.6925 - accuracy: 0.5155\n",
      "Epoch 13/20\n",
      "797/797 [==============================] - 5s 6ms/step - loss: 0.6927 - accuracy: 0.5128\n",
      "Epoch 14/20\n",
      "797/797 [==============================] - 5s 6ms/step - loss: 0.6927 - accuracy: 0.5175\n",
      "Epoch 15/20\n",
      "797/797 [==============================] - 4s 5ms/step - loss: 0.6928 - accuracy: 0.5132\n",
      "Epoch 16/20\n",
      "797/797 [==============================] - 4s 5ms/step - loss: 0.6927 - accuracy: 0.5152\n",
      "Epoch 17/20\n",
      "797/797 [==============================] - 5s 6ms/step - loss: 0.6928 - accuracy: 0.5138\n",
      "Epoch 18/20\n",
      "797/797 [==============================] - 4s 5ms/step - loss: 0.6928 - accuracy: 0.5141\n",
      "Epoch 19/20\n",
      "797/797 [==============================] - 4s 6ms/step - loss: 0.6926 - accuracy: 0.5162\n",
      "Epoch 20/20\n",
      "797/797 [==============================] - 4s 5ms/step - loss: 0.6924 - accuracy: 0.5214: 0s - loss: 0.692\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train,labels,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8baa150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM generator\n",
    "in_gen = tf.keras.Input(shape=16)\n",
    "x = Dense(20,activation=\"relu\")(in_gen)\n",
    "x = tf.keras.layers.Lambda(lambda x:tf.expand_dims(x,axis=1))(x)\n",
    "lstm_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,return_sequences=False))(x)\n",
    "dp_1 = tf.keras.layers.Dropout(0.1)(lstm_1)\n",
    "bn_1 = tf.keras.layers.LayerNormalization()(dp_1)\n",
    "rv_1 = tf.keras.layers.RepeatVector(1)(bn_1)\n",
    "# BiLSTM generator output\n",
    "gen_output = tf.keras.layers.Dense(1, activation='sigmoid')(rv_1)\n",
    "alstm = tf.keras.models.Model(in_gen, gen_output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60896a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n        loss = self.compiled_loss(\n    File \"c:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\keras\\losses.py\", line 1807, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\keras\\backend.py\", line 5158, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 1, 1) vs (None,)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HARSHV~1\\AppData\\Local\\Temp/ipykernel_4872/1373238168.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0malstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"binary_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0malstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n        loss = self.compiled_loss(\n    File \"c:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\keras\\losses.py\", line 1807, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\keras\\backend.py\", line 5158, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 1, 1) vs (None,)).\n"
     ]
    }
   ],
   "source": [
    "alstm.compile(loss=\"binary_crossentropy\",optimizer = tf.keras.optimizers.Adam(),metrics = \"accuracy\")\n",
    "alstm.fit(train,labels,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aa6cb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.2524832 , 0.24967144, 0.25566544, ..., 0.24766699, 0.25618067,\n",
       "         0.23915331],\n",
       "        [0.2478509 , 0.24602779, 0.25760196, ..., 0.24753391, 0.25572977,\n",
       "         0.23933805],\n",
       "        [0.24881709, 0.24899165, 0.2591782 , ..., 0.24756627, 0.25585762,\n",
       "         0.23927491],\n",
       "        ...,\n",
       "        [0.71028679, 0.7100581 , 0.71998847, ..., 0.7141275 , 0.72067604,\n",
       "         0.70757896],\n",
       "        [0.70985336, 0.70992214, 0.71998847, ..., 0.71444972, 0.72091398,\n",
       "         0.70798546],\n",
       "        [0.71035903, 0.71002184, 0.72023166, ..., 0.71489818, 0.72079233,\n",
       "         0.70900404]]),\n",
       " array([1, 0, 1, ..., 1, 0, 0], dtype=int64))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train_data.csv\")\n",
    "train.drop([\"Id\",\"date\"],axis=1,inplace=True)\n",
    "train = train.values\n",
    "labels = pd.read_csv(\"train_target.csv\")\n",
    "labels = labels[\"target\"].to_numpy()\n",
    "train,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "127c737c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 29)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                300       \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, 10)             0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 1, 1024)           4239360   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1, 1024)           8392704   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 1, 1024)           8392704   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 1024)             0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                10250     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,035,329\n",
      "Trainable params: 21,035,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape=29)\n",
    "x = tf.keras.layers.Dense(10,activation=\"relu\")(inputs)\n",
    "x = tf.keras.layers.Lambda(lambda x:tf.expand_dims(x,axis=1))(x)\n",
    "x = tf.keras.layers.LSTM(1024,return_sequences=True)(x)\n",
    "x = tf.keras.layers.LSTM(1024,return_sequences=True,dropout = 0.2)(x)\n",
    "x = tf.keras.layers.LSTM(1024,return_sequences=True,dropout=0.1)(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "x = tf.keras.layers.Dense(10,activation=\"relu\")(x)\n",
    "outputs = tf.keras.layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "model1 = tf.keras.models.Model(inputs,outputs)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea2d4525",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss = \"binary_crossentropy\", \n",
    "               optimizer = tf.keras.optimizers.Adam(learning_rate = 0.009),\n",
    "               metrics = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4857ad2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "797/797 [==============================] - 14s 14ms/step - loss: 0.6930 - accuracy: 0.5099\n",
      "Epoch 2/20\n",
      "797/797 [==============================] - 11s 14ms/step - loss: 0.6930 - accuracy: 0.5099\n",
      "Epoch 3/20\n",
      "797/797 [==============================] - 11s 14ms/step - loss: 0.6930 - accuracy: 0.5099\n",
      "Epoch 4/20\n",
      "797/797 [==============================] - 12s 14ms/step - loss: 0.6930 - accuracy: 0.5099\n",
      "Epoch 5/20\n",
      "117/797 [===>..........................] - ETA: 10s - loss: 0.6932 - accuracy: 0.5053"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HARSHV~1\\AppData\\Local\\Temp/ipykernel_6852/3777908700.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\harshvardhan bhosale\\onedrive\\desktop\\stock market\\venv1\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model1.fit(train,labels,epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdd01a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'Id',\n",
       " 'open',\n",
       " 'high',\n",
       " 'low',\n",
       " 'close',\n",
       " 'day',\n",
       " 'week',\n",
       " 'SMA_7',\n",
       " 'SMA_14',\n",
       " 'SMA_21',\n",
       " 'RSI_7',\n",
       " 'RSI_14',\n",
       " 'RSI_21',\n",
       " 'ATR_14',\n",
       " 'bb_mavg',\n",
       " 'bb_hband',\n",
       " 'bb_lband',\n",
       " 'PSARl_0.02_0.2',\n",
       " 'PSARs_0.02_0.2',\n",
       " 'PSARaf_0.02_0.2',\n",
       " 'PSARr_0.02_0.2',\n",
       " 'AROOND_14',\n",
       " 'AROONU_14',\n",
       " 'AROONOSC_14',\n",
       " 'STOCHk_14_3_3',\n",
       " 'STOCHd_14_3_3',\n",
       " 'MACD_12_26_9',\n",
       " 'MACDh_12_26_9',\n",
       " 'MACDs_12_26_9',\n",
       " 'KAMA_10_2_30']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2 = pd.read_csv(\"TRAINING_SET_FINAL.csv\")\n",
    "train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f3da75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2.60655205e-01,  2.58263920e-01,  2.70536100e-01, ...,\n",
       "         -2.46166935e-04,  3.53632935e-03,  2.46675093e-01],\n",
       "        [ 2.59363938e-01,  2.57928559e-01,  2.69662415e-01, ...,\n",
       "         -3.34301179e-04,  3.45275406e-03,  2.47075154e-01],\n",
       "        [ 2.60014087e-01,  2.59106853e-01,  2.71067517e-01, ...,\n",
       "         -3.42416502e-04,  3.36714993e-03,  2.47542383e-01],\n",
       "        ...,\n",
       "        [ 7.10286788e-01,  7.10058099e-01,  7.19988471e-01, ...,\n",
       "          7.03757547e-04, -1.17039007e-03,  7.14996471e-01],\n",
       "        [ 7.09853355e-01,  7.09922142e-01,  7.19988471e-01, ...,\n",
       "          6.42967848e-04, -1.00964811e-03,  7.15056197e-01],\n",
       "        [ 7.10359026e-01,  7.10021844e-01,  7.20231662e-01, ...,\n",
       "          5.87345814e-04, -8.62811656e-04,  7.15250327e-01]]),\n",
       " array([1, 0, 1, ..., 1, 0, 0], dtype=int64))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2 = pd.read_csv(\"TRAINING_SET_FINAL.csv\")\n",
    "train2.drop([\"Id\",\"date\"],axis=1,inplace=True)\n",
    "train2 = train2.values\n",
    "labels = pd.read_csv(\"train_target.csv\")\n",
    "labels = labels[\"target\"].to_numpy()\n",
    "train2,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46e6a4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.297067  , 0.29398898, 0.30530596, ..., 0.5059596 , 0.73372321,\n",
       "        0.27207134],\n",
       "       [0.29559535, 0.29360723, 0.30431998, ..., 0.49905426, 0.730624  ,\n",
       "        0.2725296 ],\n",
       "       [0.29633632, 0.29494852, 0.30590567, ..., 0.49841842, 0.72744956,\n",
       "        0.27306481],\n",
       "       ...,\n",
       "       [0.80950911, 0.80827882, 0.81252287, ..., 0.58038636, 0.55918491,\n",
       "        0.80852735],\n",
       "       [0.80901513, 0.80812406, 0.81252287, ..., 0.57562347, 0.56514567,\n",
       "        0.80859577],\n",
       "       [0.80959144, 0.80823755, 0.81279732, ..., 0.57126548, 0.57059077,\n",
       "        0.80881814]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "m = MinMaxScaler()\n",
    "m.fit(train2)\n",
    "train2 = m.transform(train2)\n",
    "train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "838dfc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25467,), (25467, 29))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels[33:]\n",
    "labels.shape,train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a48052b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "796/796 [==============================] - 17s 13ms/step - loss: 0.6942 - accuracy: 0.5079\n",
      "Epoch 2/20\n",
      "796/796 [==============================] - 10s 12ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 3/20\n",
      "796/796 [==============================] - 10s 12ms/step - loss: 0.6932 - accuracy: 0.5050\n",
      "Epoch 4/20\n",
      "796/796 [==============================] - 10s 13ms/step - loss: 0.6931 - accuracy: 0.5093\n",
      "Epoch 5/20\n",
      "796/796 [==============================] - 10s 13ms/step - loss: 0.6933 - accuracy: 0.5062\n",
      "Epoch 6/20\n",
      "796/796 [==============================] - 10s 13ms/step - loss: 0.6932 - accuracy: 0.5043\n",
      "Epoch 7/20\n",
      "796/796 [==============================] - 10s 13ms/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 8/20\n",
      "796/796 [==============================] - 10s 13ms/step - loss: 0.6932 - accuracy: 0.5055\n",
      "Epoch 9/20\n",
      "796/796 [==============================] - 10s 13ms/step - loss: 0.6932 - accuracy: 0.5064\n",
      "Epoch 10/20\n",
      "796/796 [==============================] - 10s 13ms/step - loss: 0.6932 - accuracy: 0.5048\n",
      "Epoch 11/20\n",
      "796/796 [==============================] - 10s 13ms/step - loss: 0.6932 - accuracy: 0.5051\n",
      "Epoch 12/20\n",
      "796/796 [==============================] - 10s 13ms/step - loss: 0.6932 - accuracy: 0.5055\n",
      "Epoch 13/20\n",
      "796/796 [==============================] - 10s 13ms/step - loss: 0.6931 - accuracy: 0.5064\n",
      "Epoch 14/20\n",
      "796/796 [==============================] - 10s 13ms/step - loss: 0.6933 - accuracy: 0.5008\n",
      "Epoch 15/20\n",
      "796/796 [==============================] - 10s 13ms/step - loss: 0.6932 - accuracy: 0.5059\n",
      "Epoch 16/20\n",
      "796/796 [==============================] - 10s 13ms/step - loss: 0.6932 - accuracy: 0.5048\n",
      "Epoch 17/20\n",
      "458/796 [================>.............] - ETA: 4s - loss: 0.6931 - accuracy: 0.5090"
     ]
    }
   ],
   "source": [
    "history = model1.fit(train2,labels,epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2be59e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HARSHV~1\\AppData\\Local\\Temp/ipykernel_6852/1302131920.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhelperfuncs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_curves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_curves\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Stock market\\helperfuncs.py\u001b[0m in \u001b[0;36mplot_curves\u001b[1;34m(history)\u001b[0m\n\u001b[0;32m     99\u001b[0m   '''\n\u001b[0;32m    100\u001b[0m   \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m   \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m   \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m   \u001b[0mval_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_loss'"
     ]
    }
   ],
   "source": [
    "from helperfuncs import plot_curves\n",
    "plot_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2518ba62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18cb85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6e7b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84b9941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3db662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1572ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "venv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
